#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Japan IR - æ ªä¾¡å±¥æ­´ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰
éå»5å¹´åˆ†ã®æ—¥æ¬¡æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’yfinanceã‹ã‚‰å–å¾—ã—ã¦JSONå½¢å¼ã§ä¿å­˜
20ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–
"""

import yfinance as yf
import pandas as pd
import json
import os
import time
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# è¨­å®š
INPUT_CSV_WORDPRESS = "data/wordpress_companies.csv"  # WordPressç™»éŒ²ä¼æ¥­ï¼ˆå„ªå…ˆï¼‰
INPUT_CSV_FALLBACK = "data/japan_companies_latest.csv"  # å…¨ä¼æ¥­ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
OUTPUT_DIR = "data/stock_history"
MAX_WORKERS = 3  # ä¸¦åˆ—æ•°ï¼ˆyfinance APIåˆ¶é™å¯¾ç­–ï¼‰
RETRY_DELAY = 5  # ãƒªãƒˆãƒ©ã‚¤æ™‚ã®å¾…æ©Ÿç§’æ•°
MAX_RETRIES = 2
HISTORY_PERIOD = "5y"  # 5å¹´åˆ†
PROGRESS_INTERVAL = 20
BATCH_SIZE = 50  # ãƒãƒƒãƒã‚µã‚¤ã‚º
BATCH_DELAY = 45  # ãƒãƒƒãƒé–“ã®å¾…æ©Ÿç§’æ•°

# ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
lock = threading.Lock()
progress_counter = {"success": 0, "error": 0, "total": 0}

def fetch_stock_history(code):
    """
    æŒ‡å®šã•ã‚ŒãŸè¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ã®æ ªä¾¡å±¥æ­´ã‚’å–å¾—

    Args:
        code: è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰ï¼ˆä¾‹: 7203ï¼‰

    Returns:
        dict: æ ªä¾¡å±¥æ­´ãƒ‡ãƒ¼ã‚¿ or Noneï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
    """
    ticker_symbol = f"{code}.T"

    for attempt in range(MAX_RETRIES):
        try:
            ticker = yf.Ticker(ticker_symbol)
            hist = ticker.history(period=HISTORY_PERIOD)

            if hist.empty:
                return None

            # DataFrameã‚’ãƒªã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
            data_list = []
            for date, row in hist.iterrows():
                data_list.append({
                    "date": date.strftime("%Y-%m-%d"),
                    "open": round(float(row['Open']), 2) if pd.notna(row['Open']) else None,
                    "high": round(float(row['High']), 2) if pd.notna(row['High']) else None,
                    "low": round(float(row['Low']), 2) if pd.notna(row['Low']) else None,
                    "close": round(float(row['Close']), 2) if pd.notna(row['Close']) else None,
                    "volume": int(row['Volume']) if pd.notna(row['Volume']) else None
                })

            result = {
                "code": code,
                "ticker": ticker_symbol,
                "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "period": HISTORY_PERIOD,
                "data_points": len(data_list),
                "data": data_list
            }

            return result

        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
                continue
            return None

    return None

def save_to_json(data, code):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä¿å­˜

    Args:
        data: æ ªä¾¡å±¥æ­´ãƒ‡ãƒ¼ã‚¿
        code: è¨¼åˆ¸ã‚³ãƒ¼ãƒ‰
    """
    if data is None:
        return False

    output_file = os.path.join(OUTPUT_DIR, f"{code}.json")

    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        return False

def process_company(code):
    """ä¸¦åˆ—å‡¦ç†ç”¨ã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°"""
    data = fetch_stock_history(code)
    success = save_to_json(data, code)

    # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°
    with lock:
        progress_counter["total"] += 1
        if success:
            progress_counter["success"] += 1
        else:
            progress_counter["error"] += 1

    return {"code": code, "success": success}

def main():
    print("=" * 70)
    print("Japan IR - æ ªä¾¡å±¥æ­´ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰")
    print("=" * 70)
    print(f"æœŸé–“: {HISTORY_PERIOD}")
    print(f"ä¸¦åˆ—æ•°: {MAX_WORKERS}")
    print()

    start_time = datetime.now()

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)

    # ä¼æ¥­ãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿ï¼ˆWordPresså„ªå…ˆï¼‰
    input_csv = None
    source_type = None

    if os.path.exists(INPUT_CSV_WORDPRESS):
        input_csv = INPUT_CSV_WORDPRESS
        source_type = "WordPressç™»éŒ²ä¼æ¥­"
        print(f"âœ… WordPressç™»éŒ²ä¼æ¥­ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨: {INPUT_CSV_WORDPRESS}")
    elif os.path.exists(INPUT_CSV_FALLBACK):
        input_csv = INPUT_CSV_FALLBACK
        source_type = "å…¨ä¼æ¥­ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"
        print(f"âš ï¸  WordPressä¼æ¥­ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å…¨ä¼æ¥­ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨: {INPUT_CSV_FALLBACK}")
    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: ä¼æ¥­ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"  - {INPUT_CSV_WORDPRESS}")
        print(f"  - {INPUT_CSV_FALLBACK}")
        return

    df = pd.read_csv(input_csv)
    stock_codes = df['code'].tolist()
    total = len(stock_codes)

    num_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE
    batch_wait_time = (num_batches - 1) * BATCH_DELAY
    processing_time = total / MAX_WORKERS * 2
    estimated_time = (processing_time + batch_wait_time) / 60
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {source_type}")
    print(f"å¯¾è±¡ä¼æ¥­æ•°: {total}ç¤¾")
    print(f"äºˆæƒ³æ™‚é–“: ç´„{estimated_time:.0f}åˆ†ï¼ˆãƒãƒƒãƒå¾…æ©Ÿå«ã‚€ï¼‰")
    print(f"ãƒãƒƒãƒæ•°: {num_batches}ï¼ˆ{BATCH_SIZE}ç¤¾/ãƒãƒƒãƒã€{BATCH_DELAY}ç§’é–“éš”ï¼‰")
    print()

    last_progress_print = 0

    # ãƒãƒƒãƒå‡¦ç†ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰
    batches = [stock_codes[i:i + BATCH_SIZE] for i in range(0, len(stock_codes), BATCH_SIZE)]
    total_batches = len(batches)

    for batch_idx, batch in enumerate(batches, 1):
        print(f"--- ãƒãƒƒãƒ {batch_idx}/{total_batches} ({len(batch)}ç¤¾) ---")

        # ä¸¦åˆ—å‡¦ç†
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_code = {executor.submit(process_company, code): code for code in batch}

            for future in as_completed(future_to_code):
                try:
                    future.result()
                except Exception as e:
                    with lock:
                        progress_counter["total"] += 1
                        progress_counter["error"] += 1

                # é€²æ—è¡¨ç¤º
                current_total = progress_counter["total"]
                if current_total - last_progress_print >= PROGRESS_INTERVAL or current_total == total:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    if current_total > 0:
                        eta = (elapsed / current_total) * (total - current_total) / 60
                    else:
                        eta = 0
                    print(f"[{current_total:4}/{total}] âœ… {progress_counter['success']} / âŒ {progress_counter['error']} | çµŒé: {elapsed/60:.1f}åˆ† | ETA: {eta:.0f}åˆ†")
                    last_progress_print = current_total

        # ãƒãƒƒãƒé–“ã®å¾…æ©Ÿï¼ˆæœ€å¾Œã®ãƒãƒƒãƒä»¥å¤–ï¼‰
        if batch_idx < total_batches:
            print(f"    ğŸ’¤ {BATCH_DELAY}ç§’å¾…æ©Ÿ...")
            time.sleep(BATCH_DELAY)

    # å®Œäº†ã‚µãƒãƒªãƒ¼
    end_time = datetime.now()
    elapsed = (end_time - start_time).total_seconds()

    success_count = progress_counter["success"]
    error_count = progress_counter["error"]

    print()
    print("=" * 70)
    print(f"å®Œäº†: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ‰€è¦æ™‚é–“: {elapsed/60:.1f}åˆ† ({elapsed:.0f}ç§’)")
    print(f"æˆåŠŸ: {success_count}ç¤¾ ({success_count/total*100:.1f}%)")
    print(f"å¤±æ•—: {error_count}ç¤¾")
    print(f"ä¸¦åˆ—æ•°: {MAX_WORKERS}")
    print(f"å‡ºåŠ›å…ˆ: {OUTPUT_DIR}/")
    print("=" * 70)

if __name__ == "__main__":
    main()
