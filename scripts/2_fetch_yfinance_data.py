"""
Japan IR - yfinance å…¨é …ç›®å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰
- 20ä¸¦åˆ—å‡¦ç†ã§é«˜é€ŸåŒ–
- shortName ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è¿½åŠ 
- ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å–å¾—ã§ããŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
- ã‚¨ãƒ©ãƒ¼ç†ç”±ã®è©³ç´°åŒ–
"""

import yfinance as yf
import pandas as pd
import time
from datetime import datetime
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

INPUT_CSV = "data/japan_companies_latest.csv"
OUTPUT_DIR = "output"
MAX_WORKERS = 3  # ä¸¦åˆ—æ•°ï¼ˆyfinance APIåˆ¶é™å¯¾ç­–ï¼‰
MAX_RETRIES = 2
RETRY_DELAY = 5
PROGRESS_INTERVAL = 20
BATCH_SIZE = 50  # ãƒãƒƒãƒã‚µã‚¤ã‚º
BATCH_DELAY = 45  # ãƒãƒƒãƒé–“ã®å¾…æ©Ÿç§’æ•°

# ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ãªã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
lock = threading.Lock()
progress_counter = {"success": 0, "error": 0, "total": 0}

INFO_FIELDS = [
    "shortName", "longName", "symbol", "exchange", "currency",
    "country", "city", "address1", "website", "industry", "sector",
    "longBusinessSummary", "fullTimeEmployees",
    "currentPrice", "previousClose", "open", "dayHigh", "dayLow",
    "fiftyTwoWeekHigh", "fiftyTwoWeekLow", "fiftyDayAverage",
    "twoHundredDayAverage", "volume", "averageVolume",
    "averageVolume10days", "beta",
    "marketCap", "sharesOutstanding", "floatShares",
    "impliedSharesOutstanding",
    "trailingPE", "forwardPE", "priceToBook",
    "priceToSalesTrailing12Months", "enterpriseValue",
    "enterpriseToRevenue", "enterpriseToEbitda",
    "profitMargins", "operatingMargins", "grossMargins",
    "returnOnEquity", "returnOnAssets",
    "totalRevenue", "revenuePerShare", "revenueGrowth",
    "grossProfits", "ebitda", "netIncomeToCommon",
    "earningsGrowth", "earningsQuarterlyGrowth",
    "trailingEps", "forwardEps", "bookValue",
    "dividendRate", "dividendYield", "exDividendDate",
    "payoutRatio", "fiveYearAvgDividendYield",
    "lastDividendValue", "lastDividendDate",
    "totalCash", "totalCashPerShare", "totalDebt",
    "debtToEquity", "freeCashflow", "operatingCashflow",
    "targetHighPrice", "targetLowPrice", "targetMeanPrice",
    "targetMedianPrice", "recommendationMean", "recommendationKey",
    "numberOfAnalystOpinions",
    "heldPercentInsiders", "heldPercentInstitutions",
]

def fetch_stock_data(code):
    """å˜ä¸€ä¼æ¥­ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    ticker_symbol = f"{code}.T"

    for attempt in range(MAX_RETRIES):
        try:
            ticker = yf.Ticker(ticker_symbol)
            info = ticker.info

            if not info or len(info) <= 1:
                raise Exception("Empty response")

            # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            data = {"code": code, "ticker": ticker_symbol}
            for field in INFO_FIELDS:
                data[field] = info.get(field)

            # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: æ ªä¾¡ãƒ»æ™‚ä¾¡ç·é¡ãƒã‚§ãƒƒã‚¯
            current_price = data.get("currentPrice")
            market_cap = data.get("marketCap")

            has_valid_price = current_price and current_price > 0
            has_valid_market_cap = market_cap and market_cap > 0

            if not has_valid_price and not has_valid_market_cap:
                data["status"] = "error: No valid price or market cap data"
                return data

            data["status"] = "success"
            return data

        except Exception as e:
            if attempt < MAX_RETRIES - 1:
                time.sleep(RETRY_DELAY)
                continue

            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚å–å¾—ã§ããŸãƒ‡ãƒ¼ã‚¿ã¯ä¿å­˜
            data = {"code": code, "ticker": ticker_symbol}
            if 'info' in locals() and info:
                for field in INFO_FIELDS:
                    data[field] = info.get(field)
            else:
                for field in INFO_FIELDS:
                    data[field] = None

            data["status"] = f"error: {str(e)}"
            return data

    return {"code": code, "ticker": ticker_symbol, "status": "error: Max retries"}

def process_company(code):
    """ä¸¦åˆ—å‡¦ç†ç”¨ã®ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°"""
    result = fetch_stock_data(code)

    # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ã«ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ›´æ–°
    with lock:
        progress_counter["total"] += 1
        if result.get("status") == "success":
            progress_counter["success"] += 1
        else:
            progress_counter["error"] += 1

    return result

def main():
    print("=" * 60)
    print("Japan IR - yfinance å…¨é …ç›®å–å¾—ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰")
    print("=" * 60)
    start_time = datetime.now()
    print(f"é–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ä¸¦åˆ—æ•°: {MAX_WORKERS}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    df_input = pd.read_csv(INPUT_CSV)
    stock_codes = df_input['code'].tolist()
    total = len(stock_codes)

    num_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE
    batch_wait_time = (num_batches - 1) * BATCH_DELAY
    processing_time = total / MAX_WORKERS * 2
    estimated_time = (processing_time + batch_wait_time) / 60
    print(f"å¯¾è±¡: {total}ç¤¾")
    print(f"å–å¾—é …ç›®: {len(INFO_FIELDS)}é …ç›®")
    print(f"äºˆæƒ³æ™‚é–“: ç´„{estimated_time:.0f}åˆ†ï¼ˆãƒãƒƒãƒå¾…æ©Ÿå«ã‚€ï¼‰")
    print(f"ãƒãƒƒãƒæ•°: {num_batches}ï¼ˆ{BATCH_SIZE}ç¤¾/ãƒãƒƒãƒã€{BATCH_DELAY}ç§’é–“éš”ï¼‰")
    print()

    results = []
    last_progress_print = 0

    # ãƒãƒƒãƒå‡¦ç†ï¼ˆAPIåˆ¶é™å¯¾ç­–ï¼‰
    batches = [stock_codes[i:i + BATCH_SIZE] for i in range(0, len(stock_codes), BATCH_SIZE)]
    total_batches = len(batches)

    for batch_idx, batch in enumerate(batches, 1):
        print(f"--- ãƒãƒƒãƒ {batch_idx}/{total_batches} ({len(batch)}ç¤¾) ---")

        # ä¸¦åˆ—å‡¦ç†
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_code = {executor.submit(process_company, code): code for code in batch}

            for future in as_completed(future_to_code):
                code = future_to_code[future]
                try:
                    result = future.result()
                    results.append(result)
                except Exception as e:
                    results.append({
                        "code": code,
                        "ticker": f"{code}.T",
                        "status": f"error: {str(e)}"
                    })

                # é€²æ—è¡¨ç¤º
                current_total = progress_counter["total"]
                if current_total - last_progress_print >= PROGRESS_INTERVAL or current_total == total:
                    elapsed = (datetime.now() - start_time).total_seconds()
                    if current_total > 0:
                        eta = (elapsed / current_total) * (total - current_total) / 60
                    else:
                        eta = 0
                    print(f"[{current_total:4}/{total}] âœ… {progress_counter['success']} / âŒ {progress_counter['error']} | çµŒé: {elapsed/60:.1f}åˆ† | ETA: {eta:.0f}åˆ†")
                    last_progress_print = current_total

        # ãƒãƒƒãƒé–“ã®å¾…æ©Ÿï¼ˆæœ€å¾Œã®ãƒãƒƒãƒä»¥å¤–ï¼‰
        if batch_idx < total_batches:
            print(f"    ğŸ’¤ {BATCH_DELAY}ç§’å¾…æ©Ÿ...")
            time.sleep(BATCH_DELAY)

    scrape_date = datetime.now().strftime('%Y-%m-%d')
    for r in results:
        r["scrape_date"] = scrape_date

    df_results = pd.DataFrame(results)

    # å…¨ãƒ‡ãƒ¼ã‚¿
    output_file = f"{OUTPUT_DIR}/yfinance_all_fields_{scrape_date}.csv"
    df_results.to_csv(output_file, index=False, encoding="utf-8-sig")

    # æˆåŠŸãƒ‡ãƒ¼ã‚¿ã®ã¿
    df_success = df_results[df_results["status"] == "success"]
    success_file = f"{OUTPUT_DIR}/yfinance_success_{scrape_date}.csv"
    df_success.to_csv(success_file, index=False, encoding="utf-8-sig")

    # ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¼ã‚¿
    df_errors = df_results[df_results["status"] != "success"]
    if len(df_errors) > 0:
        error_file = f"{OUTPUT_DIR}/yfinance_errors_{scrape_date}.csv"
        df_errors.to_csv(error_file, index=False, encoding="utf-8-sig")

        print()
        print("=" * 60)
        print("ã‚¨ãƒ©ãƒ¼å†…è¨³:")
        print("=" * 60)
        error_types = df_errors['status'].value_counts()
        for error_type, count in error_types.items():
            print(f"  {error_type}: {count}ç¤¾")

    end_time = datetime.now()
    elapsed = (end_time - start_time).total_seconds()

    success_count = progress_counter["success"]
    error_count = progress_counter["error"]

    print()
    print("=" * 60)
    print(f"å®Œäº†: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ‰€è¦æ™‚é–“: {elapsed/60:.1f}åˆ†ï¼ˆ{elapsed/3600:.2f}æ™‚é–“ï¼‰")
    print(f"æˆåŠŸ: {success_count}ç¤¾ ({success_count/total*100:.1f}%)")
    print(f"å¤±æ•—: {error_count}ç¤¾")
    print(f"å–å¾—é …ç›®: {len(INFO_FIELDS)}é …ç›®")
    print(f"ä¸¦åˆ—æ•°: {MAX_WORKERS}")
    print(f"å‡ºåŠ›: {output_file}")
    print("=" * 60)

if __name__ == "__main__":
    main()
